{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e133a50d-1659-4c8a-930e-ad85fff5f718",
   "metadata": {},
   "source": [
    "# Experimenting with VGAE Code\n",
    "\n",
    "Code source: https://github.com/DaehanKim/vgae_pytorch\n",
    "Paper reference: \"Variational Graph Auto-Encoders\" by Thomas N. Kipf and Max Welling, 2016\n",
    "\n",
    "## To figure out: \n",
    "- [ ] how do they pre-process their data? What form does their input data take? \n",
    "- [ ] how does GAE and GVAE work? can I implement? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdd037ad-10e2-4a51-971c-3f87862c5eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "  Downloading networkx-2.6.2-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: networkx\n",
      "Successfully installed networkx-2.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb15534e-9506-487f-bd9b-9fdc62554215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pyprojroot import here\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "\n",
    "# from input_data import load_data\n",
    "# from preprocessing import *\n",
    "# import args\n",
    "# import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fe53ca4-247c-4275-aae4-80e9e8b6a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = here(project_files=[\".here\"])\n",
    "sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c29e718-da1e-4ad7-89ac-7a455d0ab2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emma/vgae_pytorch\n"
     ]
    }
   ],
   "source": [
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e6d2148-31f1-4a1d-af32-68bf502b8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_index_file(filename):\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5aab63e-b60f-4792-8517-92bd532beacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    # load the data: x, tx, allx, graph\n",
    "    names = ['x', 'tx', 'allx', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"{}/data/ind.{}.{}\".format(root, dataset, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "    x, tx, allx, graph = tuple(objects)\n",
    "    print('graph', type(graph))\n",
    "#     print('graph', graph)\n",
    "    # graph is a dict (default dict from collections module)\n",
    "    # each key is a node, each value is a list of the adjacent nodes\n",
    "    test_idx_reorder = parse_index_file(\"{}/data/ind.{}.test.index\".format(root, dataset))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    if dataset == 'citeseer':\n",
    "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "        # Find isolated nodes, add them as zero-vecs into the right position\n",
    "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
    "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
    "        tx = tx_extended\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "    return adj, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "079c62c8-a2bb-4de5-b0fe-7eeef40b8640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph <class 'collections.defaultdict'>\n",
      "(2708, 2708)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "dataset = 'cora'\n",
    "adj, features = load_data(dataset)\n",
    "\n",
    "print(adj.shape)\n",
    "print(type(adj))\n",
    "# print(adj)\n",
    "\n",
    "# adj is a sparse matrix (scipy datatype) that contains all of the information provided in graph, see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ef78264-7aed-406c-b12f-860b2e2e799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original adjacency matrix (without diagonal entries) for later\n",
    "# TODO: look up the scipy sparse matrix format\n",
    "adj_orig = adj\n",
    "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "# print(adj_orig)\n",
    "adj_orig.eliminate_zeros()\n",
    "# print(adj_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f38a3df3-bb59-43fc-9e55-af027a733f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: understand these functions and what they're doing\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "\n",
    "def preprocess_graph(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj_ = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj_.sum(1))\n",
    "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
    "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
    "    return sparse_to_tuple(adj_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "696a0c7a-cdc2-4cab-b7d2-9a9592c3d425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[   0    0]\n",
      " [ 633    0]\n",
      " [1862    0]\n",
      " ...\n",
      " [1473 2707]\n",
      " [2706 2707]\n",
      " [2707 2707]]\n",
      "[0.25      0.25      0.2236068 ... 0.2       0.2       0.2      ]\n",
      "(2708, 2708)\n"
     ]
    }
   ],
   "source": [
    "# Some preprocessing\n",
    "adj_norm = preprocess_graph(adj)\n",
    "print(len(adj_norm))\n",
    "print(adj_norm[0]) # coords\n",
    "print(adj_norm[1]) # values\n",
    "print(adj_norm[2]) # shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:glm_env]",
   "language": "python",
   "name": "conda-env-glm_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
